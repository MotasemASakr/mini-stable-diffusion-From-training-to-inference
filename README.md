# mini-stable-diffusion-From-training-to-inference

## Mini Stable Diffusion for 16x16 Sprites
Welcome to the Mini Stable Diffusion project repository! This project focuses on training a mini model to generate 16x16 pixel sprites using Stable Diffusion. The model is trained using two different methods: with context (e.g., hero, non-hero, food, spell, side-facing) and without context.
Table of Contents

### Table of Contents
- About the Project
- Getting Started
- Training the Model
- Inference

### About the Project
This project aims to leverage the power of diffusion models to generate small-scale sprite graphics suitable for video games. By training on 16x16 pixel images, we can create diverse and detailed sprite assets efficiently. The project explores two training methodologies:
With Context: Incorporates additional labels such as character type or orientation to guide sprite generation.
Without Context: Relies solely on the sprite images themselves without any additional guiding information.
